{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-20T13:52:19.789743Z",
     "start_time": "2025-07-20T13:52:15.256336Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "# Example dataset (replace with your own if you want)\n",
    "data_dict = {\n",
    "    \"text\": [\n",
    "        \"  The staff was very kind and attentive to my needs!!!  \",\n",
    "        \"The waiting time was too long, and the staff was rude. Visit us at http://hospitalreviews.com\",\n",
    "        \"The doctor answered all my questions...but the facility was outdated.   \",\n",
    "        \"The nurse was compassionate & made me feel comfortable!! :) \",\n",
    "        \"I had to wait over an hour before being seen.  Unacceptable service! #frustrated\",\n",
    "        \"The check-in process was smooth, but the doctor seemed rushed. Visit https://feedback.com\",\n",
    "        \"Everyone I interacted with was professional and helpful.  \"\n",
    "    ],\n",
    "    \"label\": [\"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"neutral\", \"positive\"]\n",
    "}\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "data = pd.DataFrame(data_dict)\n",
    "\n",
    "# Clean the text\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower().strip()  # Convert to lowercase and remove extra spaces\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)  # Remove URLs\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove special characters\n",
    "    return text\n",
    "\n",
    "# Apply text cleaning\n",
    "data[\"cleaned_text\"] = data[\"text\"].apply(clean_text)\n",
    "\n",
    "# Convert labels to numerical values\n",
    "data[\"label\"] = data[\"label\"].astype(\"category\").cat.codes  # Converts [\"positive\", \"negative\", \"neutral\"] to [0, 1, 2]\n",
    "\n",
    "print(data.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  label  \\\n",
      "0    The staff was very kind and attentive to my ...      2   \n",
      "1  The waiting time was too long, and the staff w...      0   \n",
      "2  The doctor answered all my questions...but the...      1   \n",
      "3  The nurse was compassionate & made me feel com...      2   \n",
      "4  I had to wait over an hour before being seen. ...      0   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  the staff was very kind and attentive to my needs  \n",
      "1  the waiting time was too long and the staff wa...  \n",
      "2  the doctor answered all my questionsbut the fa...  \n",
      "3  the nurse was compassionate  made me feel comf...  \n",
      "4  i had to wait over an hour before being seen  ...  \n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-20T13:52:55.196449Z",
     "start_time": "2025-07-20T13:52:53.151255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Apply tokenization with padding\n",
    "def tokenize_function(text):\n",
    "    return tokenizer(text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Apply tokenization\n",
    "data[\"tokenized\"] = data[\"cleaned_text\"].apply(tokenize_function)\n",
    "\n",
    "# Extract tokenized features\n",
    "data[\"input_ids\"] = data[\"tokenized\"].apply(lambda x: x[\"input_ids\"])\n",
    "data[\"attention_mask\"] = data[\"tokenized\"].apply(lambda x: x[\"attention_mask\"])\n",
    "\n",
    "# Drop old tokenized column\n",
    "data = data.drop(columns=[\"tokenized\"])\n",
    "\n",
    "print(data.head())"
   ],
   "id": "3eeb931b73ae1a51",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "There was a specific connection error when trying to load bert-base-uncased:\n401 Client Error: Unauthorized for url: https://huggingface.co/bert-base-uncased/resolve/main/config.json (Request ID: Root=1-687cf4b6-65915e0b64cb9bad201a2a22;5bbd178c-bcdb-4732-84e1-d6046f4d2d03)\n\nInvalid credentials in Authorization header",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mHTTPError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:409\u001B[39m, in \u001B[36mhf_raise_for_status\u001B[39m\u001B[34m(response, endpoint_name)\u001B[39m\n\u001B[32m    408\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m409\u001B[39m     \u001B[43mresponse\u001B[49m\u001B[43m.\u001B[49m\u001B[43mraise_for_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    410\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/requests/models.py:1024\u001B[39m, in \u001B[36mResponse.raise_for_status\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1023\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m http_error_msg:\n\u001B[32m-> \u001B[39m\u001B[32m1024\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m HTTPError(http_error_msg, response=\u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[31mHTTPError\u001B[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/bert-base-uncased/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mHfHubHTTPError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/utils/hub.py:470\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    468\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(full_filenames) == \u001B[32m1\u001B[39m:\n\u001B[32m    469\u001B[39m     \u001B[38;5;66;03m# This is slightly better for only 1 file\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m470\u001B[39m     \u001B[43mhf_hub_download\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    471\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    472\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    473\u001B[39m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m==\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    474\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrepo_type\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    475\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:862\u001B[39m, in \u001B[36mhf_hub_download\u001B[39m\u001B[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001B[39m\n\u001B[32m    809\u001B[39m \u001B[38;5;129m@validate_hf_hub_args\u001B[39m\n\u001B[32m    810\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mhf_hub_download\u001B[39m(\n\u001B[32m    811\u001B[39m     repo_id: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    831\u001B[39m     local_dir_use_symlinks: Union[\u001B[38;5;28mbool\u001B[39m, Literal[\u001B[33m\"\u001B[39m\u001B[33mauto\u001B[39m\u001B[33m\"\u001B[39m]] = \u001B[33m\"\u001B[39m\u001B[33mauto\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    832\u001B[39m ) -> \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m    833\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Download a given file if it's not already present in the local cache.\u001B[39;00m\n\u001B[32m    834\u001B[39m \n\u001B[32m    835\u001B[39m \u001B[33;03m    The new cache file layout looks like this:\u001B[39;00m\n\u001B[32m    836\u001B[39m \u001B[33;03m    - The cache directory contains one subfolder per repo_id (namespaced by repo type)\u001B[39;00m\n\u001B[32m    837\u001B[39m \u001B[33;03m    - inside each repo folder:\u001B[39;00m\n\u001B[32m    838\u001B[39m \u001B[33;03m        - refs is a list of the latest known revision => commit_hash pairs\u001B[39;00m\n\u001B[32m    839\u001B[39m \u001B[33;03m        - blobs contains the actual file blobs (identified by their git-sha or sha256, depending on\u001B[39;00m\n\u001B[32m    840\u001B[39m \u001B[33;03m          whether they're LFS files or not)\u001B[39;00m\n\u001B[32m    841\u001B[39m \u001B[33;03m        - snapshots contains one subfolder per commit, each \"commit\" contains the subset of the files\u001B[39;00m\n\u001B[32m    842\u001B[39m \u001B[33;03m          that have been resolved at that particular commit. Each filename is a symlink to the blob\u001B[39;00m\n\u001B[32m    843\u001B[39m \u001B[33;03m          at that particular commit.\u001B[39;00m\n\u001B[32m    844\u001B[39m \n\u001B[32m    845\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    846\u001B[39m \u001B[33;03m    [  96]  .\u001B[39;00m\n\u001B[32m    847\u001B[39m \u001B[33;03m    └── [ 160]  models--julien-c--EsperBERTo-small\u001B[39;00m\n\u001B[32m    848\u001B[39m \u001B[33;03m        ├── [ 160]  blobs\u001B[39;00m\n\u001B[32m    849\u001B[39m \u001B[33;03m        │   ├── [321M]  403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001B[39;00m\n\u001B[32m    850\u001B[39m \u001B[33;03m        │   ├── [ 398]  7cb18dc9bafbfcf74629a4b760af1b160957a83e\u001B[39;00m\n\u001B[32m    851\u001B[39m \u001B[33;03m        │   └── [1.4K]  d7edf6bd2a681fb0175f7735299831ee1b22b812\u001B[39;00m\n\u001B[32m    852\u001B[39m \u001B[33;03m        ├── [  96]  refs\u001B[39;00m\n\u001B[32m    853\u001B[39m \u001B[33;03m        │   └── [  40]  main\u001B[39;00m\n\u001B[32m    854\u001B[39m \u001B[33;03m        └── [ 128]  snapshots\u001B[39;00m\n\u001B[32m    855\u001B[39m \u001B[33;03m            ├── [ 128]  2439f60ef33a0d46d85da5001d52aeda5b00ce9f\u001B[39;00m\n\u001B[32m    856\u001B[39m \u001B[33;03m            │   ├── [  52]  README.md -> ../../blobs/d7edf6bd2a681fb0175f7735299831ee1b22b812\u001B[39;00m\n\u001B[32m    857\u001B[39m \u001B[33;03m            │   └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001B[39;00m\n\u001B[32m    858\u001B[39m \u001B[33;03m            └── [ 128]  bbc77c8132af1cc5cf678da3f1ddf2de43606d48\u001B[39;00m\n\u001B[32m    859\u001B[39m \u001B[33;03m                ├── [  52]  README.md -> ../../blobs/7cb18dc9bafbfcf74629a4b760af1b160957a83e\u001B[39;00m\n\u001B[32m    860\u001B[39m \u001B[33;03m                └── [  76]  pytorch_model.bin -> ../../blobs/403450e234d65943a7dcf7e05a771ce3c92faa84dd07db4ac20f592037a1e4bd\u001B[39;00m\n\u001B[32m    861\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m862\u001B[39m \n\u001B[32m    863\u001B[39m \u001B[33;03m    If `local_dir` is provided, the file structure from the repo will be replicated in this location. When using this\u001B[39;00m\n\u001B[32m    864\u001B[39m \u001B[33;03m    option, the `cache_dir` will not be used and a `.cache/huggingface/` folder will be created at the root of `local_dir`\u001B[39;00m\n\u001B[32m    865\u001B[39m \u001B[33;03m    to store some metadata related to the downloaded files. While this mechanism is not as robust as the main\u001B[39;00m\n\u001B[32m    866\u001B[39m \u001B[33;03m    cache-system, it's optimized for regularly pulling the latest version of a repository.\u001B[39;00m\n\u001B[32m    867\u001B[39m \n\u001B[32m    868\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m    869\u001B[39m \u001B[33;03m        repo_id (`str`):\u001B[39;00m\n\u001B[32m    870\u001B[39m \u001B[33;03m            A user or an organization name and a repo name separated by a `/`.\u001B[39;00m\n\u001B[32m    871\u001B[39m \u001B[33;03m        filename (`str`):\u001B[39;00m\n\u001B[32m    872\u001B[39m \u001B[33;03m            The name of the file in the repo.\u001B[39;00m\n\u001B[32m    873\u001B[39m \u001B[33;03m        subfolder (`str`, *optional*):\u001B[39;00m\n\u001B[32m    874\u001B[39m \u001B[33;03m            An optional value corresponding to a folder inside the model repo.\u001B[39;00m\n\u001B[32m    875\u001B[39m \u001B[33;03m        repo_type (`str`, *optional*):\u001B[39;00m\n\u001B[32m    876\u001B[39m \u001B[33;03m            Set to `\"dataset\"` or `\"space\"` if downloading from a dataset or space,\u001B[39;00m\n\u001B[32m    877\u001B[39m \u001B[33;03m            `None` or `\"model\"` if downloading from a model. Default is `None`.\u001B[39;00m\n\u001B[32m    878\u001B[39m \u001B[33;03m        revision (`str`, *optional*):\u001B[39;00m\n\u001B[32m    879\u001B[39m \u001B[33;03m            An optional Git revision id which can be a branch name, a tag, or a\u001B[39;00m\n\u001B[32m    880\u001B[39m \u001B[33;03m            commit hash.\u001B[39;00m\n\u001B[32m    881\u001B[39m \u001B[33;03m        library_name (`str`, *optional*):\u001B[39;00m\n\u001B[32m    882\u001B[39m \u001B[33;03m            The name of the library to which the object corresponds.\u001B[39;00m\n\u001B[32m    883\u001B[39m \u001B[33;03m        library_version (`str`, *optional*):\u001B[39;00m\n\u001B[32m    884\u001B[39m \u001B[33;03m            The version of the library.\u001B[39;00m\n\u001B[32m    885\u001B[39m \u001B[33;03m        cache_dir (`str`, `Path`, *optional*):\u001B[39;00m\n\u001B[32m    886\u001B[39m \u001B[33;03m            Path to the folder where cached files are stored.\u001B[39;00m\n\u001B[32m    887\u001B[39m \u001B[33;03m        local_dir (`str` or `Path`, *optional*):\u001B[39;00m\n\u001B[32m    888\u001B[39m \u001B[33;03m            If provided, the downloaded file will be placed under this directory.\u001B[39;00m\n\u001B[32m    889\u001B[39m \u001B[33;03m        user_agent (`dict`, `str`, *optional*):\u001B[39;00m\n\u001B[32m    890\u001B[39m \u001B[33;03m            The user-agent info in the form of a dictionary or a string.\u001B[39;00m\n\u001B[32m    891\u001B[39m \u001B[33;03m        force_download (`bool`, *optional*, defaults to `False`):\u001B[39;00m\n\u001B[32m    892\u001B[39m \u001B[33;03m            Whether the file should be downloaded even if it already exists in\u001B[39;00m\n\u001B[32m    893\u001B[39m \u001B[33;03m            the local cache.\u001B[39;00m\n\u001B[32m    894\u001B[39m \u001B[33;03m        proxies (`dict`, *optional*):\u001B[39;00m\n\u001B[32m    895\u001B[39m \u001B[33;03m            Dictionary mapping protocol to the URL of the proxy passed to\u001B[39;00m\n\u001B[32m    896\u001B[39m \u001B[33;03m            `requests.request`.\u001B[39;00m\n\u001B[32m    897\u001B[39m \u001B[33;03m        etag_timeout (`float`, *optional*, defaults to `10`):\u001B[39;00m\n\u001B[32m    898\u001B[39m \u001B[33;03m            When fetching ETag, how many seconds to wait for the server to send\u001B[39;00m\n\u001B[32m    899\u001B[39m \u001B[33;03m            data before giving up which is passed to `requests.request`.\u001B[39;00m\n\u001B[32m    900\u001B[39m \u001B[33;03m        token (`str`, `bool`, *optional*):\u001B[39;00m\n\u001B[32m    901\u001B[39m \u001B[33;03m            A token to be used for the download.\u001B[39;00m\n\u001B[32m    902\u001B[39m \u001B[33;03m                - If `True`, the token is read from the HuggingFace config\u001B[39;00m\n\u001B[32m    903\u001B[39m \u001B[33;03m                  folder.\u001B[39;00m\n\u001B[32m    904\u001B[39m \u001B[33;03m                - If a string, it's used as the authentication token.\u001B[39;00m\n\u001B[32m    905\u001B[39m \u001B[33;03m        local_files_only (`bool`, *optional*, defaults to `False`):\u001B[39;00m\n\u001B[32m    906\u001B[39m \u001B[33;03m            If `True`, avoid downloading the file and return the path to the\u001B[39;00m\n\u001B[32m    907\u001B[39m \u001B[33;03m            local cached file if it exists.\u001B[39;00m\n\u001B[32m    908\u001B[39m \u001B[33;03m        headers (`dict`, *optional*):\u001B[39;00m\n\u001B[32m    909\u001B[39m \u001B[33;03m            Additional headers to be sent with the request.\u001B[39;00m\n\u001B[32m    910\u001B[39m \n\u001B[32m    911\u001B[39m \u001B[33;03m    Returns:\u001B[39;00m\n\u001B[32m    912\u001B[39m \u001B[33;03m        `str`: Local path of file or if networking is off, last version of file cached on disk.\u001B[39;00m\n\u001B[32m    913\u001B[39m \n\u001B[32m    914\u001B[39m \u001B[33;03m    Raises:\u001B[39;00m\n\u001B[32m    915\u001B[39m \u001B[33;03m        [`~utils.RepositoryNotFoundError`]\u001B[39;00m\n\u001B[32m    916\u001B[39m \u001B[33;03m            If the repository to download from cannot be found. This may be because it doesn't exist,\u001B[39;00m\n\u001B[32m    917\u001B[39m \u001B[33;03m            or because it is set to `private` and you do not have access.\u001B[39;00m\n\u001B[32m    918\u001B[39m \u001B[33;03m        [`~utils.RevisionNotFoundError`]\u001B[39;00m\n\u001B[32m    919\u001B[39m \u001B[33;03m            If the revision to download from cannot be found.\u001B[39;00m\n\u001B[32m    920\u001B[39m \u001B[33;03m        [`~utils.EntryNotFoundError`]\u001B[39;00m\n\u001B[32m    921\u001B[39m \u001B[33;03m            If the file to download cannot be found.\u001B[39;00m\n\u001B[32m    922\u001B[39m \u001B[33;03m        [`~utils.LocalEntryNotFoundError`]\u001B[39;00m\n\u001B[32m    923\u001B[39m \u001B[33;03m            If network is disabled or unavailable and file is not found in cache.\u001B[39;00m\n\u001B[32m    924\u001B[39m \u001B[33;03m        [`EnvironmentError`](https://docs.python.org/3/library/exceptions.html#EnvironmentError)\u001B[39;00m\n\u001B[32m    925\u001B[39m \u001B[33;03m            If `token=True` but the token cannot be found.\u001B[39;00m\n\u001B[32m    926\u001B[39m \u001B[33;03m        [`OSError`](https://docs.python.org/3/library/exceptions.html#OSError)\u001B[39;00m\n\u001B[32m    927\u001B[39m \u001B[33;03m            If ETag cannot be determined.\u001B[39;00m\n\u001B[32m    928\u001B[39m \u001B[33;03m        [`ValueError`](https://docs.python.org/3/library/exceptions.html#ValueError)\u001B[39;00m\n\u001B[32m    929\u001B[39m \u001B[33;03m            If some parameter value is invalid.\u001B[39;00m\n\u001B[32m    930\u001B[39m \n\u001B[32m    931\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    932\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m constants.HF_HUB_ETAG_TIMEOUT != constants.DEFAULT_ETAG_TIMEOUT:\n\u001B[32m    933\u001B[39m         \u001B[38;5;66;03m# Respect environment variable above user value\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:969\u001B[39m, in \u001B[36m_hf_hub_download_to_cache_dir\u001B[39m\u001B[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001B[39m\n\u001B[32m      0\u001B[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:1486\u001B[39m, in \u001B[36m_raise_on_head_call_error\u001B[39m\u001B[34m(head_call_error, force_download, local_files_only)\u001B[39m\n\u001B[32m   1462\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m HfFileMetadata(\n\u001B[32m   1463\u001B[39m         commit_hash=r.headers.get(constants.HUGGINGFACE_HEADER_X_REPO_COMMIT),\n\u001B[32m   1464\u001B[39m         \u001B[38;5;66;03m# We favor a custom header indicating the etag of the linked resource, and\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1474\u001B[39m         xet_file_data=parse_xet_file_data_from_response(r),  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[32m   1475\u001B[39m     )\n\u001B[32m   1478\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_get_metadata_or_catch_error\u001B[39m(\n\u001B[32m   1479\u001B[39m     *,\n\u001B[32m   1480\u001B[39m     repo_id: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   1481\u001B[39m     filename: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   1482\u001B[39m     repo_type: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   1483\u001B[39m     revision: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m   1484\u001B[39m     endpoint: Optional[\u001B[38;5;28mstr\u001B[39m],\n\u001B[32m   1485\u001B[39m     proxies: Optional[Dict],\n\u001B[32m-> \u001B[39m\u001B[32m1486\u001B[39m     etag_timeout: Optional[\u001B[38;5;28mfloat\u001B[39m],\n\u001B[32m   1487\u001B[39m     headers: Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m],  \u001B[38;5;66;03m# mutated inplace!\u001B[39;00m\n\u001B[32m   1488\u001B[39m     token: Union[\u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m],\n\u001B[32m   1489\u001B[39m     local_files_only: \u001B[38;5;28mbool\u001B[39m,\n\u001B[32m   1490\u001B[39m     relative_filename: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# only used to store `.no_exists` in cache\u001B[39;00m\n\u001B[32m   1491\u001B[39m     storage_folder: Optional[\u001B[38;5;28mstr\u001B[39m] = \u001B[38;5;28;01mNone\u001B[39;00m,  \u001B[38;5;66;03m# only used to store `.no_exists` in cache\u001B[39;00m\n\u001B[32m   1492\u001B[39m ) -> Union[\n\u001B[32m   1493\u001B[39m     \u001B[38;5;66;03m# Either an exception is caught and returned\u001B[39;00m\n\u001B[32m   1494\u001B[39m     Tuple[\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;167;01mException\u001B[39;00m],\n\u001B[32m   1495\u001B[39m     \u001B[38;5;66;03m# Or the metadata is returned as\u001B[39;00m\n\u001B[32m   1496\u001B[39m     \u001B[38;5;66;03m# `(url_to_download, etag, commit_hash, expected_size, xet_file_data, None)`\u001B[39;00m\n\u001B[32m   1497\u001B[39m     Tuple[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m, Optional[XetFileData], \u001B[38;5;28;01mNone\u001B[39;00m],\n\u001B[32m   1498\u001B[39m ]:\n\u001B[32m   1499\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Get metadata for a file on the Hub, safely handling network issues.\u001B[39;00m\n\u001B[32m   1500\u001B[39m \n\u001B[32m   1501\u001B[39m \u001B[33;03m    Returns either the etag, commit_hash and expected size of the file, or the error\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m   1506\u001B[39m \u001B[33;03m          domain of the location (typically an S3 bucket).\u001B[39;00m\n\u001B[32m   1507\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:1376\u001B[39m, in \u001B[36m_get_metadata_or_catch_error\u001B[39m\u001B[34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001B[39m\n\u001B[32m   1374\u001B[39m no_exist_dir = os.path.join(repo_cache, \".no_exist\")\n\u001B[32m-> \u001B[39m\u001B[32m1376\u001B[39m # Resolve refs (for instance to convert main to the associated commit sha)\n\u001B[32m   1377\u001B[39m if os.path.isdir(refs_dir):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/utils/_validators.py:114\u001B[39m, in \u001B[36mvalidate_hf_hub_args.<locals>._inner_fn\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    112\u001B[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001B[34m__name__\u001B[39m, has_token=has_token, kwargs=kwargs)\n\u001B[32m--> \u001B[39m\u001B[32m114\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:1296\u001B[39m, in \u001B[36mget_hf_file_metadata\u001B[39m\u001B[34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001B[39m\n\u001B[32m   1289\u001B[39m     paths.file_path.unlink(missing_ok=\u001B[38;5;28;01mTrue\u001B[39;00m)  \u001B[38;5;66;03m# delete outdated file first\u001B[39;00m\n\u001B[32m   1290\u001B[39m     _download_to_tmp_and_move(\n\u001B[32m   1291\u001B[39m         incomplete_path=paths.incomplete_path(etag),\n\u001B[32m   1292\u001B[39m         destination_path=paths.file_path,\n\u001B[32m   1293\u001B[39m         url_to_download=url_to_download,\n\u001B[32m   1294\u001B[39m         proxies=proxies,\n\u001B[32m   1295\u001B[39m         headers=headers,\n\u001B[32m-> \u001B[39m\u001B[32m1296\u001B[39m         expected_size=expected_size,\n\u001B[32m   1297\u001B[39m         filename=filename,\n\u001B[32m   1298\u001B[39m         force_download=force_download,\n\u001B[32m   1299\u001B[39m         etag=etag,\n\u001B[32m   1300\u001B[39m         xet_file_data=xet_file_data,\n\u001B[32m   1301\u001B[39m     )\n\u001B[32m   1303\u001B[39m write_download_metadata(local_dir=local_dir, filename=filename, commit_hash=commit_hash, etag=etag)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:280\u001B[39m, in \u001B[36m_request_wrapper\u001B[39m\u001B[34m(method, url, follow_relative_redirects, **params)\u001B[39m\n\u001B[32m    264\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_request_wrapper\u001B[39m(\n\u001B[32m    265\u001B[39m     method: HTTP_METHOD_T, url: \u001B[38;5;28mstr\u001B[39m, *, follow_relative_redirects: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m, **params\n\u001B[32m    266\u001B[39m ) -> requests.Response:\n\u001B[32m    267\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Wrapper around requests methods to follow relative redirects if `follow_relative_redirects=True` even when\u001B[39;00m\n\u001B[32m    268\u001B[39m \u001B[33;03m    `allow_redirection=False`.\u001B[39;00m\n\u001B[32m    269\u001B[39m \n\u001B[32m    270\u001B[39m \u001B[33;03m    A backoff mechanism retries the HTTP call on 429, 503 and 504 errors.\u001B[39;00m\n\u001B[32m    271\u001B[39m \n\u001B[32m    272\u001B[39m \u001B[33;03m    Args:\u001B[39;00m\n\u001B[32m    273\u001B[39m \u001B[33;03m        method (`str`):\u001B[39;00m\n\u001B[32m    274\u001B[39m \u001B[33;03m            HTTP method, such as 'GET' or 'HEAD'.\u001B[39;00m\n\u001B[32m    275\u001B[39m \u001B[33;03m        url (`str`):\u001B[39;00m\n\u001B[32m    276\u001B[39m \u001B[33;03m            The URL of the resource to fetch.\u001B[39;00m\n\u001B[32m    277\u001B[39m \u001B[33;03m        follow_relative_redirects (`bool`, *optional*, defaults to `False`)\u001B[39;00m\n\u001B[32m    278\u001B[39m \u001B[33;03m            If True, relative redirection (redirection to the same site) will be resolved even when `allow_redirection`\u001B[39;00m\n\u001B[32m    279\u001B[39m \u001B[33;03m            kwarg is set to False. Useful when we want to follow a redirection to a renamed repository without\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m280\u001B[39m \u001B[33;03m            following redirection to a CDN.\u001B[39;00m\n\u001B[32m    281\u001B[39m \u001B[33;03m        **params (`dict`, *optional*):\u001B[39;00m\n\u001B[32m    282\u001B[39m \u001B[33;03m            Params to pass to `requests.request`.\u001B[39;00m\n\u001B[32m    283\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    284\u001B[39m     \u001B[38;5;66;03m# Recursively follow relative redirects\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/file_download.py:304\u001B[39m, in \u001B[36m_request_wrapper\u001B[39m\u001B[34m(method, url, follow_relative_redirects, **params)\u001B[39m\n\u001B[32m    297\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m parsed_target.netloc == \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    298\u001B[39m     \u001B[38;5;66;03m# This means it is a relative 'location' headers, as allowed by RFC 7231.\u001B[39;00m\n\u001B[32m    299\u001B[39m     \u001B[38;5;66;03m# (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    302\u001B[39m     \u001B[38;5;66;03m# Highly inspired by `resolve_redirects` from requests library.\u001B[39;00m\n\u001B[32m    303\u001B[39m     \u001B[38;5;66;03m# See https://github.com/psf/requests/blob/main/requests/sessions.py#L159\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m304\u001B[39m     next_url = urlparse(url)._replace(path=parsed_target.path).geturl()\n\u001B[32m    305\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _request_wrapper(method=method, url=next_url, follow_relative_redirects=\u001B[38;5;28;01mTrue\u001B[39;00m, **params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/huggingface_hub/utils/_http.py:481\u001B[39m, in \u001B[36mhf_raise_for_status\u001B[39m\u001B[34m(response, endpoint_name)\u001B[39m\n\u001B[32m    478\u001B[39m     raise _format(HfHubHTTPError, message, response) from e\n\u001B[32m    480\u001B[39m # Convert `HTTPError` into a `HfHubHTTPError` to display request information\n\u001B[32m--> \u001B[39m\u001B[32m481\u001B[39m # as well (request id and/or server error message)\n\u001B[32m    482\u001B[39m raise _format(HfHubHTTPError, str(e), response) from e\n",
      "\u001B[31mHfHubHTTPError\u001B[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/bert-base-uncased/resolve/main/config.json (Request ID: Root=1-687cf4b6-65915e0b64cb9bad201a2a22;5bbd178c-bcdb-4732-84e1-d6046f4d2d03)\n\nInvalid credentials in Authorization header",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mOSError\u001B[39m                                   Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[4]\u001B[39m\u001B[32m, line 2\u001B[39m\n\u001B[32m      1\u001B[39m \u001B[38;5;66;03m# Load BERT tokenizer\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m2\u001B[39m tokenizer = \u001B[43mAutoTokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mbert-base-uncased\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m      4\u001B[39m \u001B[38;5;66;03m# Apply tokenization with padding\u001B[39;00m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mtokenize_function\u001B[39m(text):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/models/auto/tokenization_auto.py:1003\u001B[39m, in \u001B[36mAutoTokenizer.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001B[39m\n\u001B[32m   1001\u001B[39m         config = AutoConfig.for_model(**config_dict)\n\u001B[32m   1002\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1003\u001B[39m         config = \u001B[43mAutoConfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfrom_pretrained\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   1004\u001B[39m \u001B[43m            \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtrust_remote_code\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\n\u001B[32m   1005\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1006\u001B[39m config_tokenizer_class = config.tokenizer_class\n\u001B[32m   1007\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(config, \u001B[33m\"\u001B[39m\u001B[33mauto_map\u001B[39m\u001B[33m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mAutoTokenizer\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config.auto_map:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/models/auto/configuration_auto.py:1197\u001B[39m, in \u001B[36mAutoConfig.from_pretrained\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[39m\n\u001B[32m   1194\u001B[39m trust_remote_code = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mtrust_remote_code\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m   1195\u001B[39m code_revision = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33mcode_revision\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m-> \u001B[39m\u001B[32m1197\u001B[39m config_dict, unused_kwargs = \u001B[43mPretrainedConfig\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_config_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1198\u001B[39m has_remote_code = \u001B[33m\"\u001B[39m\u001B[33mauto_map\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mAutoConfig\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict[\u001B[33m\"\u001B[39m\u001B[33mauto_map\u001B[39m\u001B[33m\"\u001B[39m]\n\u001B[32m   1199\u001B[39m has_local_code = \u001B[33m\"\u001B[39m\u001B[33mmodel_type\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m config_dict \u001B[38;5;129;01mand\u001B[39;00m config_dict[\u001B[33m\"\u001B[39m\u001B[33mmodel_type\u001B[39m\u001B[33m\"\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m CONFIG_MAPPING\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/configuration_utils.py:608\u001B[39m, in \u001B[36mPretrainedConfig.get_config_dict\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[39m\n\u001B[32m    606\u001B[39m original_kwargs = copy.deepcopy(kwargs)\n\u001B[32m    607\u001B[39m \u001B[38;5;66;03m# Get config dict associated with the base config file\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m608\u001B[39m config_dict, kwargs = \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_get_config_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    609\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m config_dict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    610\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m {}, kwargs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/configuration_utils.py:667\u001B[39m, in \u001B[36mPretrainedConfig._get_config_dict\u001B[39m\u001B[34m(cls, pretrained_model_name_or_path, **kwargs)\u001B[39m\n\u001B[32m    663\u001B[39m configuration_file = kwargs.pop(\u001B[33m\"\u001B[39m\u001B[33m_configuration_file\u001B[39m\u001B[33m\"\u001B[39m, CONFIG_NAME) \u001B[38;5;28;01mif\u001B[39;00m gguf_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m gguf_file\n\u001B[32m    665\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    666\u001B[39m     \u001B[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m667\u001B[39m     resolved_config_file = \u001B[43mcached_file\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    668\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpretrained_model_name_or_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    669\u001B[39m \u001B[43m        \u001B[49m\u001B[43mconfiguration_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    670\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcache_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    671\u001B[39m \u001B[43m        \u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mforce_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    672\u001B[39m \u001B[43m        \u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m=\u001B[49m\u001B[43mproxies\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    673\u001B[39m \u001B[43m        \u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m=\u001B[49m\u001B[43mresume_download\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    674\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlocal_files_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    675\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtoken\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    676\u001B[39m \u001B[43m        \u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m=\u001B[49m\u001B[43muser_agent\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    677\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrevision\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    678\u001B[39m \u001B[43m        \u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubfolder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    679\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_commit_hash\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcommit_hash\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    680\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    681\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m resolved_config_file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    682\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, kwargs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/utils/hub.py:312\u001B[39m, in \u001B[36mcached_file\u001B[39m\u001B[34m(path_or_repo_id, filename, **kwargs)\u001B[39m\n\u001B[32m    254\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mcached_file\u001B[39m(\n\u001B[32m    255\u001B[39m     path_or_repo_id: Union[\u001B[38;5;28mstr\u001B[39m, os.PathLike],\n\u001B[32m    256\u001B[39m     filename: \u001B[38;5;28mstr\u001B[39m,\n\u001B[32m    257\u001B[39m     **kwargs,\n\u001B[32m    258\u001B[39m ) -> Optional[\u001B[38;5;28mstr\u001B[39m]:\n\u001B[32m    259\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    260\u001B[39m \u001B[33;03m    Tries to locate a file in a local folder and repo, downloads and cache it if necessary.\u001B[39;00m\n\u001B[32m    261\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    310\u001B[39m \u001B[33;03m    ```\u001B[39;00m\n\u001B[32m    311\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m312\u001B[39m     file = \u001B[43mcached_files\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpath_or_repo_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilenames\u001B[49m\u001B[43m=\u001B[49m\u001B[43m[\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    313\u001B[39m     file = file[\u001B[32m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m file\n\u001B[32m    314\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m file\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/transformers/utils/hub.py:553\u001B[39m, in \u001B[36mcached_files\u001B[39m\u001B[34m(path_or_repo_id, filenames, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001B[39m\n\u001B[32m    551\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _raise_exceptions_for_connection_errors:\n\u001B[32m    552\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m553\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mThere was a specific connection error when trying to load \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath_or_repo_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01me\u001B[39;00m\n\u001B[32m    554\u001B[39m \u001B[38;5;66;03m# Any other Exception type should now be re-raised, in order to provide helpful error messages and break the execution flow\u001B[39;00m\n\u001B[32m    555\u001B[39m \u001B[38;5;66;03m# (EntryNotFoundError will be treated outside this block and correctly re-raised if needed)\u001B[39;00m\n\u001B[32m    556\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(e, EntryNotFoundError):\n",
      "\u001B[31mOSError\u001B[39m: There was a specific connection error when trying to load bert-base-uncased:\n401 Client Error: Unauthorized for url: https://huggingface.co/bert-base-uncased/resolve/main/config.json (Request ID: Root=1-687cf4b6-65915e0b64cb9bad201a2a22;5bbd178c-bcdb-4732-84e1-d6046f4d2d03)\n\nInvalid credentials in Authorization header"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to Hugging Face Dataset format\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "train_dataset = train_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "test_dataset = test_dataset.remove_columns([\"text\", \"cleaned_text\"])\n",
    "\n",
    "#print(train_dataset)\n",
    "\n",
    "# Enable dynamic padding for batches\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "training_args = TrainingArguments(\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./logs\",\n",
    "    report_to=\"none\",\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "# Load pre-trained BERT model (3-class classification)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    data_collator=data_collator,\n",
    "correctly\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ],
   "id": "621828ea8e4dfb21"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
